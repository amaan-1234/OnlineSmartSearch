{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsmOonXQjlUL",
        "outputId": "5690345f-5854-4376-b0db-53a95cc80989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semantic-kernel\n",
            "  Downloading semantic_kernel-1.35.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Collecting azure-ai-projects>=1.0.0b12 (from semantic-kernel)\n",
            "  Downloading azure_ai_projects-1.1.0b2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting azure-ai-agents>=1.1.0b4 (from semantic-kernel)\n",
            "  Downloading azure_ai_agents-1.2.0b1-py3-none-any.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.3/69.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp~=3.8 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (3.12.15)\n",
            "Collecting cloudevents~=1.0 (from semantic-kernel)\n",
            "  Downloading cloudevents-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (2.11.7)\n",
            "Collecting pydantic-settings~=2.0 (from semantic-kernel)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: defusedxml~=0.7 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (0.7.1)\n",
            "Collecting azure-identity>=1.13 (from semantic-kernel)\n",
            "  Downloading azure_identity-1.23.1-py3-none-any.whl.metadata (82 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (2.0.2)\n",
            "Requirement already satisfied: openai>=1.91.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (1.98.0)\n",
            "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
            "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: websockets<16,>=13 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (15.0.1)\n",
            "Collecting aiortc>=1.9.0 (from semantic-kernel)\n",
            "  Downloading aiortc-1.13.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting opentelemetry-api~=1.24 (from semantic-kernel)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting prance<25.4.9,>=23.6.21 (from semantic-kernel)\n",
            "  Downloading prance-25.4.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pybars4~=0.9 (from semantic-kernel)\n",
            "  Downloading pybars4-0.9.13.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2~=3.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (3.1.6)\n",
            "Requirement already satisfied: nest-asyncio~=1.6 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (1.16.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (5.29.5)\n",
            "Requirement already satisfied: typing-extensions>=4.13 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel) (1.20.1)\n",
            "Collecting aioice<1.0.0,>=0.10.1 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading aioice-0.10.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting av<15.0.0,>=14.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
            "Collecting cryptography>=44.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-crc32c>=1.1 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
            "Collecting pyee>=13.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pylibsrtp>=0.10.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading pylibsrtp-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting pyopenssl>=25.0.0 (from aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading pyopenssl-25.1.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-agents>=1.1.0b4->semantic-kernel)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure-ai-agents>=1.1.0b4->semantic-kernel)\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.15.0 (from azure-ai-projects>=1.0.0b12->semantic-kernel)\n",
            "  Downloading azure_storage_blob-12.26.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting msal>=1.30.0 (from azure-identity>=1.13->semantic-kernel)\n",
            "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity>=1.13->semantic-kernel)\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting deprecation<3.0,>=2.0 (from cloudevents~=1.0->semantic-kernel)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.91.1->semantic-kernel) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.91.1->semantic-kernel) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.91.1->semantic-kernel) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.91.1->semantic-kernel) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.91.1->semantic-kernel) (1.3.1)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.0)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.7.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting werkzeug<3.1.2 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.7.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk~=1.24->semantic-kernel)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: chardet>=5.2 in /usr/local/lib/python3.11/dist-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (5.2.0)\n",
            "Collecting ruamel.yaml>=0.18.10 (from prance<25.4.9,>=23.6.21->semantic-kernel)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel)\n",
            "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0->semantic-kernel) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings~=2.0->semantic-kernel)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Collecting dnspython>=2.0.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel)\n",
            "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-ai-agents>=1.1.0b4->semantic-kernel) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.91.1->semantic-kernel) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.91.1->semantic-kernel) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.26.0)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
            "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
            "  Downloading lazy_object_proxy-1.11.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading semantic_kernel-1.35.1-py3-none-any.whl (880 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m880.8/880.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiortc-1.13.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_agents-1.2.0b1-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m202.0/202.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_projects-1.1.0b2-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.23.1-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m186.8/186.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudevents-1.12.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prance-25.4.8.0-py3-none-any.whl (36 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioice-0.10.1-py3-none-any.whl (24 kB)\n",
            "Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.26.0-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m412.9/412.9 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
            "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading pylibsrtp-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyopenssl-25.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading lazy_object_proxy-1.11.0-py3-none-any.whl (16 kB)\n",
            "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Building wheels for collected packages: pybars4, PyMeta3\n",
            "  Building wheel for pybars4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14340 sha256=5b943e65dea296b16fefe5ea43baf5a09e53dc4aec8ece7c1412915b9e2d6c8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/91/9b/2590c830475e613f1996fe9ce7876d5d31c346fb73a48838ad\n",
            "  Building wheel for PyMeta3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyMeta3: filename=PyMeta3-0.5.1-py3-none-any.whl size=16449 sha256=7e87b6c4c860ab119a5c5213a2fac1c7f616f5f37f084f25048d78cbbb3f8601\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/18/5a/5a3a19ff18c8118a8dd11204dcde08349c2bbbdd77ac45b6a7\n",
            "Successfully built pybars4 PyMeta3\n",
            "Installing collected packages: PyMeta3, parse, ifaddr, werkzeug, ruamel.yaml.clib, rfc3339-validator, python-dotenv, pyee, pybars4, pathable, lazy-object-proxy, isodate, dnspython, deprecation, av, ruamel.yaml, pylibsrtp, opentelemetry-api, jsonschema-path, cryptography, cloudevents, azure-core, aioice, pyopenssl, pydantic-settings, prance, opentelemetry-semantic-conventions, azure-storage-blob, azure-ai-agents, opentelemetry-sdk, openapi-schema-validator, msal, azure-ai-projects, aiortc, openapi-spec-validator, msal-extensions, openapi_core, azure-identity, semantic-kernel\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: pyopenssl\n",
            "    Found existing installation: pyOpenSSL 24.2.1\n",
            "    Uninstalling pyOpenSSL-24.2.1:\n",
            "      Successfully uninstalled pyOpenSSL-24.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 45.0.6 which is incompatible.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMeta3-0.5.1 aioice-0.10.1 aiortc-1.13.0 av-14.4.0 azure-ai-agents-1.2.0b1 azure-ai-projects-1.1.0b2 azure-core-1.35.0 azure-identity-1.23.1 azure-storage-blob-12.26.0 cloudevents-1.12.0 cryptography-45.0.6 deprecation-2.1.0 dnspython-2.7.0 ifaddr-0.2.0 isodate-0.7.2 jsonschema-path-0.3.4 lazy-object-proxy-1.11.0 msal-1.33.0 msal-extensions-1.3.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 openapi_core-0.19.5 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 parse-1.20.2 pathable-0.4.4 prance-25.4.8.0 pybars4-0.9.13 pydantic-settings-2.10.1 pyee-13.0.0 pylibsrtp-0.12.0 pyopenssl-25.1.0 python-dotenv-1.1.1 rfc3339-validator-0.1.4 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semantic-kernel-1.35.1 werkzeug-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install semantic-kernel transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install semantic-kernel==0.4.7 transformers\n",
        "\n",
        "from semantic_kernel import Kernel\n",
        "\n",
        "# Initialize the kernel (no memory store used here)\n",
        "kernel = Kernel()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKgvj5JJjl1c",
        "outputId": "f1a1834b-d160-4e1c-f2c5-f2ee17979159"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 0.0.1.dev0, 0.1.0.dev0, 0.2.0.dev0, 0.2.5.dev0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement semantic-kernel==0.4.7 (from versions: 0.2.1.dev0, 0.2.2.dev0, 0.2.3.dev0, 0.2.4.dev0, 0.2.6.dev0, 0.2.7.dev0, 0.2.8.dev0, 0.2.9.dev0, 0.3.0.dev0, 0.3.1.dev0, 0.3.2.dev0, 0.3.3.dev0, 0.3.4.dev0, 0.3.5.dev0, 0.3.6.dev0, 0.3.7.dev0, 0.3.8.dev0, 0.3.9.dev0, 0.3.10.dev0, 0.3.11.dev0, 0.3.12.dev0, 0.3.13.dev0, 0.3.14.dev0, 0.3.15.dev0, 0.4.0.dev0, 0.4.1.dev0, 0.4.2.dev0, 0.4.3.dev0, 0.4.4.dev0, 0.4.5.dev0, 0.4.6.dev0, 0.4.7.dev0, 0.5.0.dev0, 0.5.1.dev0, 0.9.0b1, 0.9.1b1, 0.9.2b1, 0.9.3b1, 0.9.4b1, 0.9.5b1, 0.9.6b1, 0.9.7b1, 0.9.8b1, 0.9.9b1, 1.0.0rc1, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.8.0, 1.8.1, 1.8.2, 1.8.3, 1.9.0, 1.10.0, 1.10.1, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.14.0, 1.15.0, 1.16.0, 1.17.0, 1.17.1, 1.18.0, 1.18.1, 1.18.2, 1.19.0, 1.20.0, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.22.0, 1.22.1, 1.23.0, 1.23.1, 1.24.0, 1.24.1, 1.25.0, 1.26.0, 1.26.1, 1.27.0, 1.27.1, 1.27.2, 1.28.0, 1.28.1, 1.29.0, 1.30.0, 1.31.0, 1.32.0, 1.32.1, 1.32.2, 1.33.0, 1.34.0, 1.35.0, 1.35.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for semantic-kernel==0.4.7\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SERPAPI_KEY = input(\"ğŸ”‘ Enter your SerpAPI Key: \")\n",
        "os.environ[\"SERPAPI_KEY\"] = SERPAPI_KEY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpmYasDijqjR",
        "outputId": "7202f5b0-d2b4-4611-d483-f2126dcf03bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”‘ Enter your SerpAPI Key: af0752d6e56db9700fda3c8f9f1d5f123601535c9e908c958e0a5d9b6cd1b6bc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize summarizer\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "def summarize_products(products):\n",
        "    if not products:\n",
        "        return \"No products found matching your criteria\"\n",
        "\n",
        "    # Create a shorter, more focused summary input\n",
        "    summary_items = []\n",
        "    for p in products[:3]:  # Only use top 3 for summary to avoid length issues\n",
        "        item_text = f\"{p['name'][:50]}... - ${p['price']:.2f} - {p['rating']} stars\"\n",
        "        summary_items.append(item_text)\n",
        "\n",
        "    input_text = \". \".join(summary_items)\n",
        "\n",
        "    # Only summarize if we have sufficient but not excessive text\n",
        "    if 50 <= len(input_text.split()) <= 150:  # Optimal range for summarization\n",
        "        try:\n",
        "            summary = summarizer(input_text, max_length=60, min_length=20, do_sample=False)\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            print(f\"Summarization error: {e}\")\n",
        "            return f\"Found {len(products)} great options ranging from ${min(p['price'] for p in products):.2f} to ${max(p['price'] for p in products):.2f}\"\n",
        "\n",
        "    # Return a simple summary for edge cases\n",
        "    if products:\n",
        "        return f\"Found {len(products)} noise-cancelling headphones ranging from ${min(p['price'] for p in products):.2f} to ${max(p['price'] for p in products):.2f}, with ratings from {min(p['rating'] for p in products)} to {max(p['rating'] for p in products)} stars.\"\n",
        "\n",
        "    return \"Here are your product options:\"\n",
        "\n",
        "def search_amazon(product_query, max_price):\n",
        "    \"\"\"Fixed Amazon search with correct parameters\"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"amazon\",\n",
        "        \"amazon_domain\": \"amazon.com\",\n",
        "        \"q\": product_query,  # This is the correct parameter name\n",
        "        \"api_key\": os.environ[\"SERPAPI_KEY\"]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\"https://serpapi.com/search\", params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        results = []\n",
        "        # Look for products in organic_results for Amazon\n",
        "        products_data = data.get(\"organic_results\", [])\n",
        "\n",
        "        for item in products_data[:5]:  # Get first 5 results\n",
        "            try:\n",
        "                # Extract price from various possible fields\n",
        "                price = 0\n",
        "                price_str = \"\"\n",
        "\n",
        "                # Check different price fields that Amazon might use\n",
        "                if \"price\" in item:\n",
        "                    price_str = str(item[\"price\"])\n",
        "                elif \"snippet\" in item and \"$\" in item[\"snippet\"]:\n",
        "                    # Try to extract price from snippet\n",
        "                    import re\n",
        "                    price_match = re.search(r'\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', item[\"snippet\"])\n",
        "                    if price_match:\n",
        "                        price_str = price_match.group(1)\n",
        "\n",
        "                if price_str:\n",
        "                    # Clean and convert price\n",
        "                    price = float(price_str.replace(\"$\", \"\").replace(\",\", \"\"))\n",
        "\n",
        "                    # Only include if within budget\n",
        "                    if price <= max_price and price > 0:\n",
        "                        results.append({\n",
        "                            \"name\": item.get(\"title\", \"Unknown Product\"),\n",
        "                            \"price\": price,\n",
        "                            \"rating\": float(item.get(\"rating\", 4.0)),  # Default rating\n",
        "                            \"url\": item.get(\"link\", \"\"),\n",
        "                            \"source\": \"Amazon\"\n",
        "                        })\n",
        "\n",
        "            except (ValueError, AttributeError) as e:\n",
        "                print(f\"Skipping Amazon item due to parsing error: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results[:3]  # Return top 3 matching products\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Amazon API request failed: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error searching Amazon: {e}\")\n",
        "        return []\n",
        "\n",
        "def search_walmart(product_query, max_price):\n",
        "    \"\"\"Fixed Walmart search with correct parameters\"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"walmart\",\n",
        "        \"query\": product_query,  # Correct parameter for Walmart\n",
        "        \"api_key\": os.environ[\"SERPAPI_KEY\"]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\"https://serpapi.com/search\", params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        results = []\n",
        "        # Look in organic_results for Walmart\n",
        "        products_data = data.get(\"organic_results\", [])\n",
        "\n",
        "        for item in products_data[:5]:\n",
        "            try:\n",
        "                # Extract price\n",
        "                price = 0\n",
        "                price_str = \"\"\n",
        "\n",
        "                if \"price\" in item:\n",
        "                    price_str = str(item[\"price\"])\n",
        "                elif \"snippet\" in item and \"$\" in item[\"snippet\"]:\n",
        "                    import re\n",
        "                    price_match = re.search(r'\\$(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', item[\"snippet\"])\n",
        "                    if price_match:\n",
        "                        price_str = price_match.group(1)\n",
        "\n",
        "                if price_str:\n",
        "                    price = float(price_str.replace(\"$\", \"\").replace(\",\", \"\"))\n",
        "\n",
        "                    if price <= max_price and price > 0:\n",
        "                        results.append({\n",
        "                            \"name\": item.get(\"title\", \"No title\").strip(),\n",
        "                            \"price\": price,\n",
        "                            \"rating\": float(item.get(\"rating\", 4.0)),\n",
        "                            \"url\": item.get(\"link\", \"\"),\n",
        "                            \"source\": \"Walmart\"\n",
        "                        })\n",
        "\n",
        "            except (ValueError, AttributeError) as e:\n",
        "                print(f\"Skipping Walmart item due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results[:3]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching Walmart: {e}\")\n",
        "        return []\n",
        "\n",
        "def search_ebay(product_query, max_price):\n",
        "    \"\"\"Fixed eBay search with correct parameters\"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"ebay\",\n",
        "        \"ebay_domain\": \"ebay.com\",\n",
        "        \"_nkw\": product_query,  # Correct parameter for eBay search\n",
        "        \"api_key\": os.environ[\"SERPAPI_KEY\"]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\"https://serpapi.com/search\", params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        results = []\n",
        "        # Look in organic_results for eBay\n",
        "        products_data = data.get(\"organic_results\", [])\n",
        "\n",
        "        for item in products_data[:5]:\n",
        "            try:\n",
        "                # Handle eBay's complex price structure\n",
        "                price = 0\n",
        "                price_data = item.get(\"price\", \"\")\n",
        "\n",
        "                if isinstance(price_data, dict):\n",
        "                    # eBay returns price as {'raw': '179.99', 'extracted': 179.99}\n",
        "                    price = float(price_data.get(\"extracted\", price_data.get(\"raw\", 0)))\n",
        "                elif isinstance(price_data, str):\n",
        "                    # Handle string prices\n",
        "                    import re\n",
        "                    price_match = re.search(r'(\\d+(?:\\.\\d{2})?)', price_data.replace(\"$\", \"\").replace(\",\", \"\"))\n",
        "                    if price_match:\n",
        "                        price = float(price_match.group(1))\n",
        "                elif isinstance(price_data, (int, float)):\n",
        "                    price = float(price_data)\n",
        "\n",
        "                if price > 0 and price <= max_price:\n",
        "                    results.append({\n",
        "                        \"name\": item.get(\"title\", \"No title\").strip(),\n",
        "                        \"price\": price,\n",
        "                        \"rating\": float(item.get(\"rating\", 4.0)),\n",
        "                        \"url\": item.get(\"link\", \"\"),\n",
        "                        \"source\": \"eBay\"\n",
        "                    })\n",
        "\n",
        "            except (ValueError, AttributeError, TypeError) as e:\n",
        "                print(f\"Skipping eBay item due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results[:3]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching eBay: {e}\")\n",
        "        return []\n",
        "\n",
        "def search_google_shopping(product_query, max_price):\n",
        "    \"\"\"Enhanced Google Shopping search with better error handling\"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"google_shopping\",\n",
        "        \"q\": product_query,\n",
        "        \"api_key\": os.environ[\"SERPAPI_KEY\"],\n",
        "        \"location\": \"United States\",\n",
        "        \"hl\": \"en\",\n",
        "        \"gl\": \"us\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\"https://serpapi.com/search\", params=params, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        results = []\n",
        "        shopping_results = data.get(\"shopping_results\", [])\n",
        "\n",
        "        print(f\"Google Shopping found {len(shopping_results)} results\")\n",
        "\n",
        "        for item in shopping_results[:15]:  # Process more results\n",
        "            try:\n",
        "                # Extract price with multiple fallbacks\n",
        "                price = 0\n",
        "\n",
        "                # Try different price fields\n",
        "                if \"extracted_price\" in item and item[\"extracted_price\"]:\n",
        "                    price = float(item[\"extracted_price\"])\n",
        "                elif \"price\" in item:\n",
        "                    price_str = str(item[\"price\"])\n",
        "                    import re\n",
        "                    price_match = re.search(r'(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', price_str.replace(\"$\", \"\"))\n",
        "                    if price_match:\n",
        "                        price = float(price_match.group(1).replace(\",\", \"\"))\n",
        "\n",
        "                # Only include if within budget and price is valid\n",
        "                if 0 < price <= max_price:\n",
        "                    results.append({\n",
        "                        \"name\": item.get(\"title\", \"Unknown Product\")[:100],  # Limit name length\n",
        "                        \"price\": price,\n",
        "                        \"rating\": float(item.get(\"rating\", 4.2)),  # Slightly lower default\n",
        "                        \"url\": item.get(\"link\", \"\"),\n",
        "                        \"source\": item.get(\"source\", \"Google Shopping\")\n",
        "                    })\n",
        "\n",
        "            except (ValueError, AttributeError, TypeError) as e:\n",
        "                continue  # Skip silently to reduce noise\n",
        "\n",
        "        print(f\"Google Shopping filtered to {len(results)} valid results\")\n",
        "        return results[:8]  # Return top 8\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error searching Google Shopping: {e}\")\n",
        "        return []\n",
        "\n",
        "def collect_all_products(product_name, max_price):\n",
        "    \"\"\"Collect products from all sources\"\"\"\n",
        "    print(f\"ğŸ” Searching across multiple platforms for: {product_name} under ${max_price}\")\n",
        "\n",
        "    products = []\n",
        "\n",
        "    # Search each platform\n",
        "    print(\"Searching Amazon...\")\n",
        "    products.extend(search_amazon(product_name, max_price))\n",
        "\n",
        "    print(\"Searching Walmart...\")\n",
        "    products.extend(search_walmart(product_name, max_price))\n",
        "\n",
        "    print(\"Searching eBay...\")\n",
        "    products.extend(search_ebay(product_name, max_price))\n",
        "\n",
        "    # Always try Google Shopping for more comprehensive results\n",
        "    print(\"Searching Google Shopping...\")\n",
        "    products.extend(search_google_shopping(product_name, max_price))\n",
        "\n",
        "    # Remove duplicates and sort by rating and price\n",
        "    seen_products = set()\n",
        "    unique_products = []\n",
        "\n",
        "    for product in products:\n",
        "        # Create a simple identifier for deduplication\n",
        "        identifier = (product[\"name\"].lower().strip(), product[\"price\"])\n",
        "        if identifier not in seen_products:\n",
        "            seen_products.add(identifier)\n",
        "            unique_products.append(product)\n",
        "\n",
        "    # Sort by rating (descending) then by price (ascending)\n",
        "    unique_products = sorted(unique_products, key=lambda x: (-x[\"rating\"], x[\"price\"]))\n",
        "\n",
        "    return unique_products[:8]  # Return top 8 overall for better variety\n",
        "\n",
        "def run_bot(user_input):\n",
        "    \"\"\"Main bot function - now synchronous for Jupyter compatibility\"\"\"\n",
        "    # Extract product + price\n",
        "    if \"under $\" in user_input:\n",
        "        product_name = user_input.split(\"under $\")[0].replace(\"Best\", \"\").strip()\n",
        "        try:\n",
        "            max_price = float(user_input.split(\"under $\")[1].strip())\n",
        "        except (IndexError, ValueError):\n",
        "            max_price = 9999\n",
        "            print(\"âš ï¸ Couldn't parse price limit, using $9999\")\n",
        "    else:\n",
        "        product_name = user_input.strip()\n",
        "        max_price = 9999\n",
        "\n",
        "    print(f\"Searching for: {product_name} under ${max_price}\")\n",
        "\n",
        "    products = collect_all_products(product_name, max_price)\n",
        "    print(f\"Found {len(products)} products\")\n",
        "\n",
        "    if not products:\n",
        "        print(\"âš ï¸ No products found matching your criteria\")\n",
        "        print(\"ğŸ’¡ Try:\")\n",
        "        print(\"- Using more general search terms\")\n",
        "        print(\"- Increasing your budget\")\n",
        "        print(\"- Checking if the API has access to shopping data\")\n",
        "        return\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nğŸ” Top Product Recommendations:\\n\")\n",
        "    for i, p in enumerate(products, 1):\n",
        "        print(f\"{i}. {p['name']}\")\n",
        "        print(f\"   ğŸ’° Price: ${p['price']:.2f}\")\n",
        "        print(f\"   â­ Rating: {p['rating']}/5.0\")\n",
        "        print(f\"   ğŸ›’ Source: {p['source']}\")\n",
        "        print()\n",
        "\n",
        "    # Generate summary\n",
        "    try:\n",
        "        summary = summarize_products(products)\n",
        "        print(\"ğŸ“ Summary:\")\n",
        "        print(summary)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Could not generate summary: {e}\")\n",
        "\n",
        "# Test function for Jupyter/Colab\n",
        "def test_search():\n",
        "    \"\"\"Test function that works in Jupyter notebooks\"\"\"\n",
        "    # Make sure your API key is set\n",
        "    if \"SERPAPI_KEY\" not in os.environ:\n",
        "        print(\"âš ï¸ Please set your SERPAPI_KEY environment variable\")\n",
        "        return\n",
        "\n",
        "    # Test with the example\n",
        "    run_bot(\"Best noise cancelling headphones under $300\")\n",
        "\n",
        "# For direct script execution\n",
        "if __name__ == \"__main__\":\n",
        "    test_search()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGuSw3yWsyq-",
        "outputId": "e860b58a-8621-416b-a1ca-24cb87e32797"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for: noise cancelling headphones under $300.0\n",
            "ğŸ” Searching across multiple platforms for: noise cancelling headphones under $300.0\n",
            "Searching Amazon...\n",
            "Amazon API request failed: 400 Client Error: Bad Request for url: https://serpapi.com/search?engine=amazon&amazon_domain=amazon.com&q=noise+cancelling+headphones&api_key=af0752d6e56db9700fda3c8f9f1d5f123601535c9e908c958e0a5d9b6cd1b6bc\n",
            "Searching Walmart...\n",
            "Searching eBay...\n",
            "Searching Google Shopping...\n",
            "Google Shopping found 43 results\n",
            "Google Shopping filtered to 13 valid results\n",
            "Found 8 products\n",
            "\n",
            "ğŸ” Top Product Recommendations:\n",
            "\n",
            "1. Anker Soundcore Q20i Hybrid Active Noise Cancelling Headphones\n",
            "   ğŸ’° Price: $49.99\n",
            "   â­ Rating: 4.8/5.0\n",
            "   ğŸ›’ Source: Best Buy\n",
            "\n",
            "2. Anker Soundcore Space One Wireless Noise Cancelling Headphones\n",
            "   ğŸ’° Price: $79.99\n",
            "   â­ Rating: 4.7/5.0\n",
            "   ğŸ›’ Source: Newegg.com - Anker Official Store\n",
            "\n",
            "3. Sony Noise Canceling Wireless Headphones\n",
            "   ğŸ’° Price: $99.99\n",
            "   â­ Rating: 4.6/5.0\n",
            "   ğŸ›’ Source: Sony\n",
            "\n",
            "4. Bose QuietComfort Wireless Noise Cancelling Headphones\n",
            "   ğŸ’° Price: $229.00\n",
            "   â­ Rating: 4.6/5.0\n",
            "   ğŸ›’ Source: Bose\n",
            "\n",
            "5. JBL Tune 670NC Noise Cancelling Wireless On-Ear Headphones\n",
            "   ğŸ’° Price: $79.95\n",
            "   â­ Rating: 4.4/5.0\n",
            "   ğŸ›’ Source: Walmart - Seller\n",
            "\n",
            "6. Skullcandy Hesh ANC Noise Wireless Over-Ear Headphones\n",
            "   ğŸ’° Price: $94.99\n",
            "   â­ Rating: 4.4/5.0\n",
            "   ğŸ›’ Source: Best Buy\n",
            "\n",
            "7. Bose QuietComfort Ultra Earbuds Wireless Noise Cancelling\n",
            "   ğŸ’° Price: $299.00\n",
            "   â­ Rating: 4.3/5.0\n",
            "   ğŸ›’ Source: Bose\n",
            "\n",
            "8. RAND MCNALLY CLEARDRYVE 210 PREMIUM CONVERTIBLE NOISE-CANCELLING BLACK HEADSET\n",
            "   ğŸ’° Price: $34.99\n",
            "   â­ Rating: 4.0/5.0\n",
            "   ğŸ›’ Source: eBay\n",
            "\n",
            "ğŸ“ Summary:\n",
            "Found 8 noise-cancelling headphones ranging from $34.99 to $299.00, with ratings from 4.0 to 4.8 stars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVl9AB-0wmgi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}